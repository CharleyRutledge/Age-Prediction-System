# Age Prediction System by Charley Rutledge 
## How to download
Please click the **Code** button and Click **Download Zip** or clone the repository.

## How to run
**Please Note: There is a link that allows you open the notebook directly in the Final_year_Project.ipynb**

### Step 1
After opening the notebook, connect to a runtime by clicking **connect** in the top right corner or in the navbar in the top left, select **Runtime** and Please select **T4 GPU**. For this project Google Colab Pro was used which gave access to High RAM and more powerful GPU's.

### Step 2
after connecting to a runtime, click the **runtime** button again select **Run all**. 
This will execute the cells of code inside the notebook.

## Restrictions
This project uses google Drive to store the dataset. The dataset can be downloaded by clicking [DropBox Link](https://www.dropbox.com/scl/fi/ebg1vr6bng0ayri5hf5bi/combined_faces_train_augmented-001.zip?rlkey=ege15x9dvoop3f053d51d18az&dl=0) for ease of access however mounting the driver is necessary as there is over 234,000 images and this is a storage issue.
The dataset was obtained from [Skillcate](https://www.kaggle.com/datasets/skillcate/merged-augmented-utk-faces-facial-age-dataset)

Running the project will produce different results each time so the values may not reflect the project that is stored in the repository.

## Viewing the results
The folder Results has stored the trained model and the weights along with any charts and results generated by the model.

# Age detection and prediction

## Introduction

Artificial intelligence (AI) has been a dominant subject in the modern media and has forever
changed the way we develop technology, notably AI powered chatbots are being adopted by
companies to handle customer interactions, removing any further human intervention(Raj,
2023)This type of modern intelligence is closely coupled with machine learning (ML) where
large amounts of data play a crucial role in training and testing models and enabling
algorithms to determine optimal outcomes for specific tasks based on that data.

Considering the utilization of AI systems across various demographics, it is imperative to
address the need for appropriate protections concerning users under the age of 18.
Safeguarding minors and vulnerable populations from potential misuse or evasion of existing
protocols is a cause for concern. Integrating security measures such as age verification
becomes essential to mitigate and prevent underage access to websites with age-related
restrictions. Current age-gating methods such as a self- reported age declaration methods are
insufficient and inadequate and call for more rigorous verification methods which in turn,
guarantee compliance with age-specific guidelines Negreiro (2023)

### Digital age of consent in Ireland

The current age for digital consent in Ireland, according to the data protection commission, is

Any individuals under this age limit must have their parent guardians’ consent to access
and use services online. However, it is not clear on how the company that owns the app or
service that the child wants to use confirm that they have obtained parental consent before
collecting personal data from children under this designated age. Social media platforms have
also become an integral part of many children and adolescents’ lives; However, these
platforms may present exposure to harmful content such as cyberbullying or exploitation.
These platforms also collect data about children including, personal information and
browsing habits. The General Data Protection regulation (GDPR) imposes a comprehensive
requirement on every organization engaged in personal data processing for both adults and
children.(Data Protection Commission, 2023).


Consent is one of the six legal bases under GDPR, the following legal bases:

- Consent
- Contract
- Legal obligation
- Vital interests
- Public task
- Legitimate interest
(Guidance on Legal Bases for Processing Personal Data | Data Protection Commission, 2023)

It is recognised that if a company uses a different legal base other than consent that parental
consent is not necessary. (Data Protection Commission, 2023). Hence, a critical aspect of
parental responsibility involves examination of all the social medial platforms, games and
other online services that capture a child’s interest. It is also important to take into
consideration that children may divulge their personal data without obtaining parental
consent which highlights the issue of poor communication between parent and child
regarding use of online services. (Data Protection Commission, 2023).

The data protection commission offers advice on how to check if these companies require
consent to collect children’s data by getting parents to prioritize reading the Terms of
Service (TOS) agreements. These agreements contain information about data handling and
privacy practises which can impact a child’s digital data and experience, parents can hope to
equip themselves with the knowledge to make informed decisions and therefore safeguard
their children’s privacy and data effectively.

It is evident that the language employed in the vast majority of TOS is inherently difficult to
understand and interpret for a significant portion of users. This presents a dilemma for users
as to use the service offered or purchased online, they have little choice but to accept the
terms and conditions and as a result will overlook agreements within the digital document.
Additionally, a compelling aspect that is presented by these long legal agreements is that
parents find themselves who find themselves in a constant stream of consent requests every
time their child goes online may simply opt for yes to all which as a result will heighten the
potential risks and privacy of the child in regard to usage of data.


### Effectiveness of Parental Controls.

Parental controls are like a toolbox for parents and guardians. They contain important
features to help them protect and manage children’s online activities. These features can do
things like filter out inappropriate content, restrict access to certain websites or applications
or offer monitoring services so parents can observe what their kids are doing online.

Parents can use these tools to customize what their child sees based on the age and maturity
level, but it is necessary to assess the effectiveness of these tools, where they fall short and
the psychological and ethical consideration of using them. Parents also have to consider
keeping up with the fast-paced digital landscape.

An article on user interactions by McFarlin, Buffardi and Schumacher, found that when users
were asked to use built-in parental controls on devices like a television with a V-Chip, an
Xbox 360 console, a Firefly mobile phone and a TiVo digital recorder, they encountered
challenges and had difficulty in navigating and managing user interfaces, parents also found
the rating systems confusing. The article then suggests improving the design of these
interfaces and rating systems could encourage greater user, leading to a more positive
outcome. (McFarlin, Buffardi and Schumacher, 2007).

### Age Verification

Children nowadays are quick to learn about the internet and can use apps that are available on
tablets or smartphones. An advertising standards authority survey discovered that out of 24
children, twenty of them who were aged between 11 and 15 years old registered on a social
media platform using a falsified age. (Advertising Standards Authority | Committee of
Advertising Practice, 2020).

As instructed by GDPR, companies can gather and process children’s data with parental
consent but do not have strict age verification processes in place. As a result, children can
easily bypass these procedures uses by applications to verify the age of its users.
In the European Union (EU), there exists a range of ages at which member states can set the
digital consent age for individuals with the minimum being 13 and the maximum at 16. For
Instance, Belgium and Denmark have chosen the age to be 13, France set the age for 15 while
Germany, Ireland and the Netherlands have set it at 16. This diversification of age presents a
challenge to developers who must tailor their applications to comply with different age
requirements in various countries. (Cansu Caglar, 2021).


### Types of verification

Self-declaration – Typically websites will present the user with a question asking if they are
over 18. The user can select yes or no and access to the website will be determined on the
users answer. There is no further verification and can be easily bypassed. (Caglar, C. 2021)

Debit/credit card – The user will enter their card details and a small amount e.g., € 0.01 will
be deducted. Used by ecommerce sites and banks, this method cannot truly verify if the card
owner is legitimate. (Caglar, C. 2021)

Biometrics – using AI and machine learning, biometrics can now produce more accurate
results specifically when identifying facial features in order to estimate the age of a person
and confirm they are over 18. However, they can be prone to error and exploitation, if an
adult’s face is required to access an application, then a child can simply hold up a picture of
an adult and the model can determine that they are over 18 and permit access. (Caglar, C.
2021)

Parental consent – This method requires that an adult register on a system and verify that
they are a guardian or parent using official documents such as Passport, government ID etc so
that their child can access that system. (Caglar, C. 2021)

Digital ID – Governments can issue an online tool that verifies the identity of an individual
so they can access digital services. In Ireland MyGovID provides this type of identity service
so users can access medical, revenue and social welfare services provided by the state.
(Caglar, C. 2021)

Age verification application – France is the first EU country that will implement a
government issued age verification app. The purpose is to prevent underage users from
accessing adult-content websites and apps. Websites must allow and implement this change
or risk being banned from France. Strauss, M. (2023)


### The euCONSENT project

The EU is currently building an age-appropriate code of conduct to be used in the Digital
services act, this act addresses illegal content, targeted advertising, smart contracts, and
content moderation. The EU co-founded the euCONSENT project and is building a browser-
based age verification system that was successfully tested by 2000 children, adults, and
parents from 5 European states. Oprea, A. (2022).

As of 24/4/2023, the pilot phase of the project has concluded as 2000 adults and children who
tested the system on dummy websites representing various age-restricted content. Users had
to verify their age only once and subsequent websites could access this information without
requiring them to go through the verification process again. euConsent (2023)

The euCONSENT project is now aiming toward real-world implementation and aims to
allows users of any approved age verification provider to access age-gated websites without
needing multiple checks. To integrate this, euCONSENT plans to include this functionality
with the next version of the European Digital Identity Wallet(eIDAS). euConsent (2023)

## Using Biometrics and neural networks as a solution to age verification issues.

### Neural networks

Neural networks or artificial neural networks (ANNs) are a pivotal component within the
domain of machine learning and serve as the cornerstone of deep learning algorithms. Their
architecture supposedly loosely replicates signalling neurons from the human brain.
(Ibm.com, 2023)

ANNs are characterized by their layered structure, comprising of an **input layer** , **hidden
layers,** and an **output layer.** Within these nodes, individual nodes establish connections with
one another based on weights. An active state is achieved when the output of an individual
node surpasses a predefined weight which is then passed to another layer, if the weight is not
met then there is no data transfer. (Ibm.com, 2023)


Neural networks are most effective when provided access to large amounts of training data.
This enables them to learn continuously and eventually reach a high accuracy provided the
data set is of high quality. These algorithms can be fine-tuned for better precision which in
turn can provide acceleration for fields such as data processing and reduce the time demands
for intensive tasks such as speech and image recognition. (Ibm.com, 2023)

### Convolutional neural networks.

Convolutional neural networks (CNNs) were designed to enhance the effectiveness and
efficiency of image data processing. This improvement stems from the incorporation of
convolutional operations for feature extraction from images. An important attribute of
conventional layers, called parameter sharing, enables the utilization of identical weights for
processing various sections of an image. (Opencv.org, 2023)

This helps the model identify feature patterns that remain consistent despite translation
invariance, which refers to the capability of disregarding positional shift of the target within
an image. (Soni, 2019).
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/35361b4b-20c8-4997-ac1c-a4816288ecd8)

```
Figure 1: Convolutional layers displaying a feature extractor and classifier (Opencv.org,
2023). In this image the VGG-16 convolutional base is a model that was developed in 2014
for the ImageNet Large Scale visual recognition challenge competition. The model achieved
92.7% accuracy on the ImageNet. (GeeksforGeeks, 2020).
```

## Convolutional neural network and why it is suitable for age prediction

The achievements of a convolutional neural network in facial recognition, image
classification and object recognition are widely recognised, this project seeks to use the
capabilities of CCNs for the automatic prediction of age and gender using labelled facial
images. CCNs are characterized by their multiple convolutional layers, each building upon
the output of its predecessor, resulting is a robust and accurate output. (B. Abirami, Subashini
and V. Mahavaishnavi, 2020).

Convolutional neural networks groups pixels together, allowing them to discern temporal
patterns more effectively. CCNs use learnable parameters eliminating the gap between feature
extraction and the regression phase, In the CCN framework, all stages are optimized to
minimize estimation errors. (Yi, Lei and Li 2015).

Due to the networks ability to extract meaningful features and optimize them for more
accurate and efficient estimations, makes it a suitable solution for age detection systems.

### Convolutional layer

The CCN architecture comprises several fundamental building blocks that includes
convolutional layers, pooling layers, and fully connected layers. A typical CNN structure is
characterized by the repetition of a series of convolutional layers followed by a pooling layer
that results in one or more fully connected layers. The transformation process of converting
input data into output by traversing through the layers is known as forward propagation
(Yamashita et al., 2018).


### Forward propagation

Forward propagation is where data travels a neural network in a unidirectional manner, this
results in the final generation of an output. The data is received by the hidden layers,
processed, and then proceed to the next layer, this prevents the data from traversing in a loop
ensuring that there is a meaningful output. (H2o.ai, 2023).

### The Convolution Operation

Within a convolutional layer, a convolution operation involves the utilization of a small filter
to process input data. This is typically used for image processing, the kernel used is known as
the Sobel kernel, which is used to detect vertical edges. Within CNNs, the elements within
the filter represent weights that the network learns during its training process. (Opencv.org,
2023)

The operation places a Kernel over a portion of the input and conducts elementwise
multiplication between the filter elements and their corresponding counterparts in the input.
The filter continues to move across the image which corresponds to a stride of one.
(Opencv.org, 2023)

![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/27dedc92-c0b5-4454-aef3-03e9c3a65b99)

```
Figure 2 : Illustration of a convolution operation Mishra (2020)
```

The filter location is called a receptive field which is where a CNN feature is looking
specifically at. (The,H 2017), the result represents a single value which signifies the outcome
of the convolutional operation for a given filter location.

![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/911bba6a-6d0c-483a-88dc-eab95a39b430)

```
Figure 3 : Convolutional operation calculates a single value (Opencv.org, 2023)
```
The output result is typically smaller size compared to the input slice. This is due to how the
filter is positioned over the input, ensuring it does not extend beyond the input boundaries, it
can do this because it employs padding.. (Opencv.org, 2023)

### Padding

The concept of padding entails the addition of extra pixels along the perimeter of the input
image. This assists the mitigation of aggregation bias during the convolution operation, this
ensures that every pixel is included. (Knowledgehut.com, 2023)


### Max Pooling

It is common practise to reduce the spatial dimensions of data through the utilization of
pooling layers. These layers are used after a convolutional layer to limit the size of activation
maps and to extract the features of activation maps. The result of pooling is the reduction of
the number of parameters within the convolutional neural network as it shrinks the input size
for subsequent layers. This reduction of parameters streamlines the computational demands
during training and reduces the issue of over fitting. (Yamashita et al., 2018)
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/98ee6551-a386-4d34-92e1-764b16810846)

```
Figure 4: max pooling example (Opencv.org, 2023)
```
In the case of a pooling later for a given location, the values undergo a max pool operation
which results in the maximum value in the output, as illustrated above, there is a four x four
input slice and a two x two filter with a stride of 2. The corresponding result is a two x two
downsampled representation of the input slice. This retains the most prominent features
within the data without introducing additional model parameters. (Opencv.org, 2023)


### Fully connected layer

The output feature map results from the final convolution or pooling layer and undergoes a
process known as flattening. This converts the feature maps into a one-dimensional (1D)
array or vector of numerical values. These vectors are connected to one or many fully
connected dense layers. A dense layer is linked to every output through learnable weights.
Once the features which are extracted by the convolutional layers and downsampled by the
pooling layers are prepared, they are processed by a subset of fully connected layers, this
dense layer map extracted features to the final outputs of the network which correspond to
probabilities associated with each class in tasks like classification. (Yamashita et al., 2018).

Each fully connected layer is followed by a nonlinear activation function, often ReLU
(Rectified Linear Unit), when applied to an image, removes all elements with black or
negative values and leaves only those with positive values represented by grey and white
(Superdatascience.com, 2023).

### Training the network

The training of a neural network involves the iterative process of identifying optimal kernels
within convolutional layers and fine tuning the weights in dense layers to minimize the
differences between the models predicted output and the known ground truth labels within a
training dataset. This optimization procedure relies on the utilization of the back propagation
algorithm. (Yamashita et al., 2018)

The evaluation of a model’s performance concerning a particular set of kernels and weights,
is quantified using the loss function during the forward propagation stage on a training
dataset. Following this, the learnable parameters undergo adjustments in response to the loss
value, this process is facilitated by a back propagation in conjunction with gradient descent.
(Yamashita et al., 2018).


### Greyscaling Images

The model will be trained using images that will be greyscaled. Greyscaling can improve the
processing of images if there are constraints on memory and bandwidth. This can often lead
to better performance with more accurate results however using colour could increase the
amount of training required to achieve optimal performance. Kanan and Cottrell (2012).

### Loss function

Loss function calculates the error between a predicted output and the ground truth for a
training set. The loss function is used to update the weights so the model can be more
accurate. The loss is calculated by computing the difference the elements of the ground truth
vector and the elements of the predicted output. Each term is squared, and the total sum
represents the total error. (Opencv.org, 2023).

### Gradient descent

Gradient descent is an optimization algorithm, and its primary purpose is to iteratively adjust
the learnable parameters, specifically the kernels and weights of a neural network with the
objective of minimizing the loss function. The gradient of the loss function provides guidance
by indicating the direction in which the function exhibits the most significant increase. Each
learnable parameter is updated in the opposite direction of the gradient and the magnitude of
the update is influences by an adjustable step size dictated by a hyperparameter known as the
learning rate. (Yamashita et al., 2018)
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/540ad401-68b2-4182-b440-7d6e4fbae0f1)

```
Figure 5: Gradient update of a parameter formula (Yamashita et al., 2018)
```
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/12951faf-5e1d-4bd4-a566-4c5b45f9f2dd)

```
Figure 6: a convex shaped loss function with a single tunable parameter called W
(Opencv.org, 2023)
```
The vertical axis portrays the value of the loss function while the horizontal axis illustrates
the values of a single trainable weight denoted as **We1**. The analysis is divided into left and
right plots. In the left plot, after computing the slope of the loss function at the point
corresponding to the current weight estimate **We1** , it is shown that the gradient is **negative**.
The optimal course of action involves increasing the weight to approach the desired value of
**Wo**. Therefore, the direction of adjust must move in the opposite direction of the negative
gradient. (Opencv.org, 2023).

In the right plot, if **We1** surpasses the optimal value of **Wo** , the gradient is **positive** , the
appropriate strategy is to decrease the value of the current weight to converge toward **Wo.**
(Opencv.org, 2023).


### Comparison of different neural networks

A Binary neural network(BNN) is a category of deep neural network(DNN), known for its
efficient use of memory resources. (Mani, A. Saravanaselvan and Arumugam, 2022)

The BNN approach is compared against a human-based image recognition system operating
in the infrared (IR) spectrum. Parameters such as kernel count and synaptic links in 32-bit
DNNs are used in the comparison. The primary modules within the BNN system are designed
to evaluate the power consumption of these functional blocks. (Mani, A. Saravanaselvan and
Arumugam, 2022)

Quantum Neural networks(QNN) comprises of several layers, these layers exhibit varying
sensitivities to size and complexity. QNNs typically extract hierarchical features and can
distribute thinner layers and deeper layers with more semantic features. (Mani, A.
Saravanaselvan and Arumugam, 2022),

For real-time object detection analysis, CNN classifier performs significantly better and is
more accurate when compared to QNN or BNN neural networks. (Mani, A. Saravanaselvan
and Arumugam, 2022).

## Dataset - UTK Face

UTKFace is a large dataset with an age range from 0 to 116 years containing over twenty
thousand images with age, gender, and ethnicity annotations.

### Labels

The labels are embedded in the filename and are formatted as such : age, gender, race, date
and time.

- Age will range from 0 to 116.
- Gender is 0 (male) and 1 (female).
- Race is from 0 to 4, noted as white, Black, Asian, Indian and others (Hispanic, Latino,
    middle eastern).
- Date and time formatted as yyyymmddHHMMSSFFF.


This dataset is the most suitable for this project as there are age annotations, however it must
be recognised that this dataset is collected from the internet and there may be a possibility
that these images have been gathered without the explicit consent or knowledge of the
original users which may raise ethical concerns regarding privacy of data and consent. Future
researchers must exercise caution and ethical responsibility when utilizing such data.

There is other datasets like Digiface: 1 million that may show promise with future research.
This dataset has been collected in an ethical manner and with permissions. However, Digiface
lacks age annotations which could be addressed through a manual labelling process and due
to this, the dataset would not be suitable for this project.

## Programming language and libraries

### TensorFlow

TensorFlow is an open-source machine learning library for large-scale machine learning.
Created by Google Brain in 2015, TensorFlow can run and train neural networks for digit
classification, image recognition, data embeddings, natural language processing and
simulations. TensorFlow can run on a local and in the cloud environment and performs faster
on Googles TensorFlow processing unit (TPU) Yegulalp (2018).

Due to the language being supported by google, it is well documented and will be suitable for
this project.

### OpenCV

OpenCV (Open computer vision) is an open-source computer vision and machine learning
library dedicated to providing a framework for computers vision tasks and advancing the
integration of computer perception in commercial and personal applications. The library
contains over 2500 optimised algorithms that range from classical to innovative techniques
which can be used in face and object detection, human action classification in videos, camera
movement tracking and object motion detection. OpenCV (2018)


## Analysis and Design

### Use Case Diagram
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/08645c4e-fd65-4e79-a300-688803661a84)


```
Figure 7: Age detection system use case diagram
```

**Use case name :** Age Detection System

**Entry Conditions :**

1. A user interacts with the system by capturing a photo of themselves
2. The user invokes the Age estimation system function

**Flow of Events:**

1. The system displays a screen and a button that captures a photo of the user
2. The user has their photo taken and the system displays another button that submits the
    photo to the model.
3. The system is sent the photo by the user and compares it to the photos trained in the
    model.
4. If the age range of the user can be estimated:
    a. The age range is displayed to the user on the user interface.
5. If the age range cannot be detected:
    a. The system displays an error message to the user interface.

### Sequence diagram
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/59ebb10d-5f82-4af2-8bfb-0c7e7b8eb339)

```
Figure 8: Age detection sequence diagram showing how the user interacts with the systems
```

**User initiation:**

The user who is the primary actor, interacts with the user interface to begin the age estimation
process.

**Photo Capture:**

The user interface prompts the user to capture their photo.

**Age estimation System:**

The user interface passes the captured photo to the age estimation system for processing. The
machine learning model, which has been trained on a diverse age-annotated dataset, extracts
features to estimate the user’s age range.

**Result Display:**

If the system estimates the user's age range, it displays the age range to the user through the
interface, If age estimation is not possible, the system displays an error message.

## Conclusion:

The age estimation system displays age ranges to the user and handles errors gracefully while
having a clear and instructional user interface using a convolutional neural network.


## Implementation Chapter

### Introduction

The purpose of this document is to provide a comprehensive overview of the technical
information utilized within the project, evaluate the overall quality of the design, identify any
existing flaws, propose possible solutions, and critically analyse the project's outcomes,
including a detailed description of its completion.

## Technical Information

### Google Colab

```
Feature Description
Platform Google Colab
Environment Jupyter notebook
Functionality Code execution (Python), with free
computer resources including GPUs
Suitability for machine learning High
```
### TensorFlow

```
Feature Description
Tool TensorFlow
Type Open-source machine learning library
(developed by Google)
Capabilities Complex calculations, deep learning, data
visualization
```
### Keras

```
Feature Description
Tool Keras
Type Deep learning API
Benefits User-friendly, reduces coding effort
```

```
Philosophy "Progressive disclosure of complexity"
(Team, 2024)
Key Point Enables quick coding with the option to add
complex functionalities later
```
### PIP

```
Feature Description Reference
Tool PIP
Type Python package manager
Function Fetches and installs external
libraries (modules)
Benefit Simplifies code by
managing external libraries
Explanation "import" searches and binds
the library, reducing code
needed to call it
```
```
Python Software Foundation
(2024)
```

### Kaggle public API

```
Feature Description Reference
Tool Kaggle
Type Online community platform
Target Users Machine learning programmers & data scientists
Functionalities - Testing & writing code
```
- Competing in challenges
- Sharing solutions (notebooks)
- Interacting with datasets (public API)
**Benefit** Collaborative environment for data science &
    machine learning
**API Key** - Free to generate for registered users
**- JSON format
containing user
information
Example
Structure**

```
{"username":"name","key":"key_is_written_here"} Kaggle (n.d.)
```
### Files management library

```
Feature Description Reference
Tool files module Python Software Foundation
(2024b)
Type Python module
Function Accesses disk files and
directories
Context Used in Google Colab to
interact with local files
```

### OpenCV

```
Feature Description Reference Reason for Use
Tool OpenCV OpenCV (2018)
Type Computer vision
library & machine
learning software
Capabilities - Over 2500
algorithms for image
& video processing
```
- Face detection &
    recognition

(^) ✓

- Classification &
    detection

(^) ✓

### NumPy

```
Feature Description Reference Reason for Use Benefits
NumPy Mathematical
library
```
```
(Refsnes Data,
2024)
```
- Efficient
manipulation of
numerical data
(arrays,
matrices)
    - Enables
    efficient
    operations on
    image data
    (pixel values)


### Matplotlib

```
Feature Description Reference Reason for
Use
```
```
Benefits
```
```
Matplotlib.pyplot Python
visualization
library
```
```
(Hunter et al.,
2012)
```
- Generate and
display various
plots (images,
histograms)
    - Enables
    visual
    exploration
    and analysis of
    data
**Feature** Matplotlib.pyplot
**Type** Python
visualization
library

### Pillow image processing library

```
Feature Description Reference Reason for Use Benefits
Pillow Image
processing
library
```
```
(Clark, 2024) - Efficient
access to image
data
```
- Supports
various image
file formats
**Tool** Pillow
**Type** Image
processing
library
**Capabilities** - Image
processing


### OS

```
Feature Description Reference Reason for Use Benefits
OS Import Python module - Enables
interaction with
the operating
system for file
access
Tool os module
Type Python module
Function Interact with
operating
system
functionality
```
### Progress bar

```
Feature Description Reference Reason for Use Benefits
Tqdm.notebook Progress bar
library
```
```
(Costa-Luis,
2015)
```
- Provides
visual feedback
on progress of
iterations
    - Improves user
    experience by
    displaying
    progress
**Tool** tqdm.notebook
**Type** Python library
**Function** Display
progress bar
during iterations


### Kaggle

```
Feature Description Reference Reason for Use Benefits
Kaggle
(Import & API
JSON file)
```
```
Access and
interact with
Kaggle datasets
```
- Download and
    use datasets
       - Collaborate
       and share data

```
Tool Kaggle module
& JSON file
Type Python module
&
Authentication
file
Function Interact with
Kaggle API
```
### Pandas Series and DataFrame

```
Feature Description Reference Reason for Use Benefits
Pandas Data analysis
library
```
- Efficient data
    manipulation
    and analysis
       - Offers various
       data structures
       and
       functionalities
**Tool** Pandas
**Type** Python library
**Data
Structures**
- Series (1D
array)
**- DataFrame
(2D array)
Function** Store,
manipulate, and
analyse data


### Seaborn

```
Feature Description Reference Reason for Use Benefits
Seaborn Data
visualization
library
```
```
(seaborn, 2012) - Create visually
appealing and
informative data
visualizations
```
- More user-
friendly and
aesthetically
pleasing
visualizations
compared to
Matplotlib
**Tool** Seaborn
**Type** Python library
**Function** Create various
data
visualizations
**Compatibility** Integrates well
with Panda’s
data


### Sequential layers

```
Feature Description Reference Reason for Use Benefits
Sequential Deep learning
library
component
```
```
(Team, 2024) - Build and
manage
sequential
neural network
models
```
- Simple and
intuitive way to
define
sequential
models
**Tool** Keras
**Type** Deep learning
library
**Function** Create and
manage
sequential
neural network
models

### CV2 google Colab patch

```
Feature Description Reference Reason for Use Benefits
cv2_imshow Code patch for
Google Colab
```
```
(Google.com,
2019)
```
- Enables
displaying
images in
Google Colab
notebooks
    - Workaround
    for displaying
    images in
    environments
    where
    cv2.imshow is
    not available by
    default
**Tool** cv2_imshow
**Type** Code patch
**Function** Display images
in Google Colab


### Splitting the dataset

```
Feature Descriptio
n
```
```
Referenc
e
```
```
Reaso
n for
Use
```
```
Benefits
```
```
sklearn.model_selection.train_test_spli
t
```
```
Machine
learning
library
component
```
```
(scikit-
learn,
2024)
```
- Split
data
into
trainin
g and
testing
sets
    - Ensures
    unbiased
    evaluatio
    n of
    machine
    learning
    models
**Tool** scikit-learn
**Type** Machine
learning
library
**Function** Split data
for training
and testing
models


### Converting categorical data into one hot encodes format

```
Feature Description Reference Reason for Use Benefits
keras.utils.
To_categorica l
```
```
Deep learning
library
component
```
```
(GeeksforGeeks,
2020)
```
- Convert
categorical data
into one-hot
encoded format
    - Prepares
    categorical data
    for use in
    machine
    learning models
**Tool** Keras
**Type** Deep learning
library
**Function** Convert
categorical data
into binary
vectors for
model training

### Visualizing a neural network structure

```
Feature Description Reference Reason for
Use
```
```
Benefits
```
```
keras.utils.plot_model Deep learning
library
component
```
```
(Team, 2024) - Visualize
the structure
of a neural
network
model
```
- Improves
understanding
and debugging
of complex
models
**Tool** Keras
**Type** Deep learning
library
**Function** Generate and
save an image
representation
of the model
architecture


### Extracting features for convolutional layers

```
Feature Description Reference Reason for Use Benefits
Keras.layers.Conv2D Deep learning
layer
```
```
(Team, 2024) - Extract
features from
images using
convolutional
filters
```
- Captures
spatial
relationships in
image data

```
Tool Keras
Type Deep learning
layer
Function Performs
convolution
operations on
2D data
(images)
Arguments - Input shape
(width, height,
channels)
```

### AveragePooling2D

```
Feature Descriptio
n
```
```
Referenc
e
```
```
Reason for
Use
```
```
Benefits
```
```
Keras.layers.AveragePooling2
D
```
```
Deep
learning
layer
```
```
(Team,
2024)
```
- Reduce the
dimensionalit
y of 2D data
(images)
using average
pooling
    - Reduces
    computationa
    l cost and
    captures
    dominant
    features
Performs downsampling by
averaging values within a
window
- "Same" padding ensures
output has same dimensions as
input
Tool Keras
Type Deep
learning
layer
Function Performs
average
pooling on
2D data
(images)
Arguments - pool_size
(window
size)
- strides
(step size
between
windows)


- padding
("valid" or
"same")

### Global Average Pooling 2D

```
Feature Descriptio
n
```
```
Referenc
e
```
```
Reason for
Use
```
```
Benefits
```
```
Keras.layers.GlobalAveragePoolin
g2D
```
```
Deep
learning
layer
```
```
(Cloud,
2023)
```
- Reduce the
dimensionalit
y of 2D data
(images)
    - Reduces
    model
    complexit
    y and
    captures
    global
    features
**Tool** Keras
**Type** Deep
learning
layer
**Function** Calculates
the
average
value for
each
feature
map in the
input
**- Unlike flattening, preserves
spatial information**


### Dense layer

```
Feature Description Reference Reason for Use Benefits
Dense Deep learning
layer
```
```
(Mamon, n.d.) - Perform linear
transformations
and
classifications
```
- Versatile layer
for building
various neural
network
architectures
**Tool** Keras
**Type** Deep learning
layer
**Function** Connect each
neuron to all
neurons in the
previous layer
**Other Names:** Fully connected
layer
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/9a1d3ca1-da27-4964-8977-15f9f31ca86e)

```
Figure
1:Example of a Dense layer Mamon (n.d.)
```

### ModelCheckpoint

```
Feature Description Reference Reason for
Use
```
```
Benefits
```
```
ModelCheckpoint Deep learning
callback
```
```
(Team, 2024) - Save model or
weights
periodically
during training
```
- Captures
model progress
at different
stages
**Tool** Keras
**Type** Deep learning
callback
**Function** Saves models
based on user-
defined criteria
**Options** - Save
frequency
(epoch or
batch)
- Best model
selection based
on specific
metric
- Save
complete
model or
weights only
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/67d3121e-e1a7-4351-8ddc-941db9aa356d)

```
Figure 2: Example of model callback use in the project
```

### Categorical crossentropy

```
Feature Description Reference Reason for Use Benefits
Categorical
Crossentropy
```
```
Loss function (Team, 2024) - Measure the
difference
between
predicted and
actual
categorical
labels
```
- Suitable for
multi-class
classification
problems

```
Tool N/A (algorithm)
Type Loss function
Function Calculate loss
based on one-
hot encoded
labels and
predictions
Applicability Multi-class
classification
problems
```

### One hot encoding

```
Feature Description Reference Reason for Use Benefits
One-hot
encoding
```
```
Data encoding
technique
```
```
(Brownlee,
2017)
```
- Convert
categorical
variables into
binary vectors
    - Enables
    efficient
    processing of
    categorical data
    in machine
    learning models
**Tool** N/A (technique)
**Type** Data encoding
technique
**Function** Represent each
category with a
unique binary
vector
**Benefits** - Avoids
assumptions
about inherent
hierarchy
between classes
- Enables
efficient
processing by
models
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/46dc23dd-5d24-4c1b-b6a4-3ce5544a0f89)

```
Figure 3: Example of one hot encoding Brownlee (2017)
```

### Adam optimizer

```
Feature Description Reference Reason for Use Benefits
Adaptive
Moment
Estimation
(Adam)
```
```
Optimization
algorithm
```
```
(Kingma et al.,
2014)
```
- Efficiently
minimize loss
function in
neural network
training
    - Efficient, low
    memory usage,
    and handles
    large datasets

```
Tool N/A (algorithm)
Type Optimization
algorithm
Function Update model
parameters
based on
calculated
gradients
Benefits - Efficient
updates
```
- Low memory
    requirements
- Handles large
    datasets well
- Resistant too
    noisy or sparse
    gradients


### Metrics

```
Feature Description Reference Reason for Use Benefits
Categorical
Accuracy
```
```
Model
evaluation
metric
```
```
(Team, 2024) - Measure the
proportion of
correct
predictions for
multi-class
classification
```
- Simple and
intuitive metric
for assessing
model
performance

```
Tool Keras
Type Model
evaluation
metric
Function Calculate the
percentage of
predictions
matching true
labels
Sample
Weighting
```
```
Evaluation
technique
```
```
(Team, 2024) - Assign
different
weights to
different data
points during
evaluation
```
- Focus on
specific data
points or
address
imbalanced
datasets
**Tool** N/A (technique)
**Type** Evaluation
technique
**Function** Modify the
contribution of
each data point
to the overall
evaluation
metric


```
Options - None
(default): equal
weight to all
data points
```
- 0: exclude
    specific data
    points from
    calculation

### Fitting the model

Using model.fit(), the model trains the data based on the arguments passed.
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/c1ec1cc0-34de-4d6d-acae-276da3a6f4ce)

```
Figure 4: Usage of fit in the project
```

```
Arguments:
X_train_age is a Numpy array containing the age inputs.
Y_train_age_onehot is the encoded training labels
Batch size is the amount of data per update. (Team, 2024)
Validation data() is the data which to evaluate loss at the end of each epoch. This is purely
used for testing and not for training. (Team, 2024)
Epochs is the number of iteration to train the model. (Team, 2024)
Callbacks is a list of callback instances; this is used to store information such as weights or
the model. (Team, 2024)
Shuffle is of Boolean type and defines if the training data should be shuffled before each
epoch. (Team, 2024)
```
### Plotting the model

```
Feature Description Reference Reason for
Use
```
```
Benefits
```
```
Matplotlib.pyplot Python visualization
library
```
```
(Hunter et
al., 2012)
```
- Generate
and display
various plots
(images,
histograms)
    - Enables
    visual
    exploration
    and analysis
    of data
**In the context of
the project:**
- Used to plot model
performance metrics
(categorical accuracy,
loss, val_loss,
val_category_accuracy
- Visualizes training
and validation
performance over
epochs
**Tool** Python library
**Type** Python library
**Function** Generate various plots


**Additional Notes:** - Plots loss curves to
understand model
learning and
performance.

- Plots accuracy
    curves to assess
    prediction accuracy.
- Minimizing loss
    leads to more accurate
    predictions.
- Convergence in loss
    curves indicates
    optimal model state.
- Convergence in loss
    curves indicates
    optimal model state.
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/de599c7c-46d1-44e7-aaa0-f3fefa396e4e)

```
Figure 5: Example of loss and accuracy plots from the project
```

### Confusion matrix

```
Feature Description Reference Reason for Use Benefits
Confusion
Matrix
```
```
Evaluation tool (W3schools.com,
2024)
```
- Visualize and
analyse model
performance in
classification
tasks
    - Identifies
    where errors
    occur and
    provides
    insights into
    model
    behaviour
**Tool** N/A (technique)
**Type** Evaluation tool
**Function** Organize
predicted and
actual labels in
a table
**Interpretation** - Rows: True
classes
**- Columns:
Predicted
classes
- True values:
Correct
predictions
- False values:
Incorrect
predictions
Accuracy** Model
evaluation
metric

```
(W3schools.com,
2024)
```
- Measure
overall
proportion of
correct
predictions
    - Simple and
    intuitive metric
    for assessing
    model
    performance
**Tool** N/A (metric)


**Type** Model
evaluation
metric
**Function** Calculate the
percentage of
correct
predictions
**Precision** Model
evaluation
metric

```
(W3schools.com,
2024)
```
- Measure the
proportion of
true positives
among
predicted
positives
    - Useful for
    assessing the
    model's ability
    to avoid false
    positives

**Tool** N/A (metric)
**Type** Model
evaluation
metric
**Function** Calculate the
percentage of
correctly
predicted
positives
**Recall** Model
evaluation
metric

```
(W3schools.com,
2024)
```
- Measure the
proportion of
actual positives
that were
correctly
identified
    - Useful for
    assessing the
    model's ability
    to avoid false
    negatives

**Tool** N/A (metric)
**Type** Model
evaluation
metric


```
Function Calculate the
percentage of
true positives
out of all actual
positives
F1-Score Model
evaluation
metric
```
```
(W3schools.com,
2024)
```
- Harmonic
mean of
precision and
recall
    - Balances
    precision and
    recall, useful
    for imbalanced
    datasets
**Tool** N/A (metric)
**Type** Model
evaluation
metric
**Function** Calculate the
harmonic mean
of precision and
recall
The matrix will create nine quadrants:

```
False Negative X3 Centre Left, Bottom Right and centre.
False Positive X3 Top Right and middle Right
True Negative Top Left
True Positive X2 Bottom Right and Centre
```

## Design Quality

The headers in this section represent the different sections in the project in order. Any
replication of commands or code will not be included and mentioned only once e.g. !mkdir
etc.

### Library install and imports section

The Try/excepts blocks ensure that the necessary packages are installed of missing and make
the code more robust. Each import is separated improving its readability and maintainability.
Including comments that explain the purpose of the code make it easier to understand.

If the notebook crashes or is stopped and run again, then this code block will run again which
will produce redundancy in installation.

Additional considerations would include better evaluation of design of performance and
resource constraints and the possible usage of a requirements file for package management.

### Mounting the google drive

The code in this section is short and straightforward which makes it easy to understand and
use. The try...expect block catches any exception and provides an error message.

Granting access to the google drive through a mount raises security concerns as there can be
personal files stored.

Additional improvements that could be made is including more troubleshooting steps based
on the specific type of error.

### Removing the sample data directory and files

This directory is stored on all notebooks by default, but it is not required so this is removed
from the project as it is redundant.


### Printing the GPU information

Th code is straightforward to use and implement, providing basic information about GPU
availability. However, it relies on the Nvidia-smi command which is specific to Nvidia
command which is used specifically to Nvidia GPUs.

Additional improvements that could be made includes tailoring the information retrieved
based on specific needs.

### Loading the augmented data

The code is short and readable, it iterates through all the files in the directory, extracts the age
labels, images and paths from filenames, loads images and stores them in separate lists, the
tqdm library provides a visual indicator of the processing progress.

It assumes a specific format for file names and will not work with different naming
conventions so mimicking the format of the current file name is necessary.

Improvements could be made such as adding more exceptions when dealing with files and
use more flexible methods for extracting labels or allow the user to configure the expected
filename format.

### Displays the occurrences of ages in increments of 5.

It achieves the goal of analysing age distribution and ages are not modified ensuring the data
integrity.

The presentation of the data could be improved by created a more insightful and presentable
user interface.

### Sampling the amount of images of 1 years old by 70%

Uses pandas and handles duplicates appropriately.

If there are duplicates the values will increase instead of being sampled or decreased.

It is difficult to decide how much data is sampled however 70% is what the project needs to
use to product a good result.


### Create an age range

This code is easy to understand and has a straightforward implementation.

The amount of age ranges are hardcoded, and the amount of age ranges could be increased
however it was decided to be 3 classes due to the scope of the project.

### Applying greyscaling to images

The code in simple and concise in design.

It does not handle any errors like invalid image input or conversion failures.

An improvement would be to check if the input is a valid image and raise an appropriate
exception of not.

### Converting the list to a numpy array and convert the age values to a numpy array

The code loads images from specified paths, resizes them and adds the greyscaling to them.
They are then stored in a numpy array (x) it also extracts the age labels and converts them
into a numpy array(y).

The code uses a mixture of different libraries to achieve the desired goal and could be further
improved by using less library and adhere to fewer or a single library for consistency and
clarity however do to the amount of learning and training this requires, the code is sufficient
to meet its goal.

### Convolutional Neural network architecture

The sequential architecture provides a clear, understandable structure, Keras is flexible with
different types of architecture and hyperparameters.

A high level of knowledge is required, and further study is required to create a custom design
for a convolutional neural network. There was many iterations and attempts at trying to build
one, but further knowledge and study is necessary for this. The code architecture that was
selected, produced the best results within an acceptable timeframe and is referenced and
includes the appropriate usage license.


### Training the model

The model is trained during this code execution, parameters such as the training data and
labels and test data and labels are added for training and validation to the model, the batch
size which represents the number of samples processed per iteration, epochs which is the
number of times the model iterates over all the data, callbacks lists the callback defined in the
checkpoint method. Shuffle is set to true for better generalization.

Requires a GPU and sufficient RAM for training and a further study can assist in improving
the training methods implemented.

### Evaluating the model on the test dataset

This line evaluates the performance of the loaded model on the testing dataset. It returns
metrics and prints the corresponding metrics.

An area for improvement would be to include better descriptions and to ensure that a GPU
with high RAM is evaluating the data. This is a section of the project which crashes due to
the size of the test dataset.

### Create and displays a confusion matrix

This code analyses and generates a confusion matrix which reports in the model’s
performance.

A consistent error occur when there is not enough memory when generating the matrix

**Internal Error: Failed copying input tensor from /job:
localhost/replica:0/task:0/device:CPU:0 to /job: localhost/replica:0/task:0/device:GPU:0
in order to run _EagerConst: Dst tensor is not initialized.**

This error implies the need for higher memory and a GPU. This was a result of the computer
credits running out in google Colab, with the current GPUs provided by Google Colab, It still
can occasionally crash.


### Maps the class integers to a string

This function takes the numerical values associated with the classes defined in the age range
and maps it to a corresponding descriptive.

### Testing the model on its own data

This code iterates through the first 10 images in the dataframe, displaying each image, its
original age and the model prediction.

Since this is the same data, it was used to train on, the accuracy of the predictions is improved
but there is room for the accuracy to be better due to some of images being incorrectly
classified to the wrong age range. Further research will be needed to fully understand why
this is occurring and more education is required.

## Design Decisions

### Removing the user interface

Originally this desktop app was to be designed to have a basic user interface with a header,
one image box, two buttons and a result text box

The purpose of the image box is to display the image that has been uploaded. The header will
display the application name. The upload button once clicked, will allows the user to upload
an image to the system. The submit button will begin the age prediction process. The result
will be displayed in the result text box, this will show the predicted age of the person in the


image. The image below is a wireframe designed wireframePro by Mockflow.
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/f965d75c-a35f-4d04-a6fa-db443cb5078f)

```
Figure 6: Wireframe of proposed user interface
```
This user interface was not implemented due to a lack of time and would also need further
upskilling in UI design with the python programming language. The project runs in Google
Colab and due to the runtime and usage credits, having a runtime open for a long period of
time is expensive.

### Changes to the dataset

The project utilized the UTKFace dataset, encompassing approximately 20,000 images
capturing individuals across a wide age spectrum, from 0 to 114 years. These images were
standardized to a resolution of 200px by 200px. However, the dataset exhibited certain biases
towards particular age groups, necessitating a careful sampling approach to ensure balanced
representation. To address this, images were selectively removed, particularly those depicting
individuals of certain ages where data scarcity was observed.

Subsequently, efforts were made to diversify the dataset by applying image preprocessing
techniques such as greyscaling and Gaussian blur. Despite these interventions, the desired
level of diversity and richness in the dataset was not achieved.

To enhance dataset diversity and augment sample size, an additional dataset was integrated,
obtained from the combined UTKFace and Facial Age datasets curated by Skillcate AI. This


augmented dataset was pivotal in enriching the training data by introducing synthetic
variations through techniques like image rotation.

Augmentation, as employed in this project, involves the application of modifications to
existing datasets, including but not limited to image rotations. By creating synthetic data
points, augmentation effectively expands the dataset's size, thereby facilitating more robust
model training and improving its generalization capabilities.
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/7d06c453-4f2f-45ef-ae9e-d6e096470c39)

```
Figure 7: Example of data augmentation AI (2022)
```
This created a dataset of approximately 234,000 images. These images were stored on a
publicly a google drive and were linked and accessed using my google drive when mounted
in Google Colab.


### Removal of the UTKFace dataset

Originally, only the UTKFace dataset was selected but due to its size and imbalance of data,
the decision was to use the combined dataset that was curated by Skillcate, containing over
234,000 facial data images. The UTKFace dataset was going to be used as a test set but it was
decided to completely remove the UTKFace dataset due to the size of the dataset, the
preparation needed, and it was expensive to run and train the model each time to figure out
issues.

Since the dataset was split into test and train, the test set was sufficient to use and more
computationally efficient in terms of time.

### Using Colab Pro

The project used the free version of Google Colab however due to the size of the dataset and
the use of encoding, the RAM and GPU that was assigned kept crashing, hindering the
project. Google Colab Pro was used. This provided 100 compute units, faster GPU’s more
memory. This was a paid subscription and cost €11.38 per month.

### Tensorboard not used

Tensorboard was not used due to the learning curve needed and the plotting that is used in the
project is sufficient to demonstrate the accuracy of the model.

### Lack of user interface

Due to time constraints, a user interface was not created. This could have been implemented
given enough time however time was spent on improving the model.

### Storage of dataset

Dropbox was originally suggested to be used to store the dataset but due to the change of
dataset during the implementation phase, the dataset was stored on google drive.


## Completed System

1. Import and install libraries to use in the project.
2. Mounting the google drive to access dataset.
3. Removing the sample data directory found by default in the notebook.
4. Printing the current GPU information.

### A Nvidia-SMI GPU with High RAM was enabled to allows the project to run.
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/39174bd1-75b7-4b75-a919-a5e5e9e57efb)

```
Figure 8: GPU information used in project.
```
5. Creating a folder to store the dataset.
6. Download and extract the dataset to a zip folder.
7. Unzip the folder and move it to the appropriate storage folder.
8. Count the number of images in the dataset.
9. Unmount the google drive.
10. Load the dataset.
11. Create and manipulating the dataset.
12. Create a charts folder to store snapshots of different charts created.
13. Create statistical data about the dataset


### Generate a histogram and KDE plot for the ages dataframe
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/237c13b1-6f01-4b5e-bcd4-ba19516b6cd8)

```
Figure 9: Visualization of the amount of ages in the dataset used in the project.
```
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/e6c77399-12d1-403f-aaed-a945b241ebc6)

```
Figure 10: Visualization of the dataset that had values over 50 reduced in the project.
```
Displays the occurrence of ages in increments of 5 to find out the precise imbalances in the
dataset. Sample the amount of images of 26-year-olds by 60%.

![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/4dade5fe-a2aa-48d7-9992-0cd6868f66e9)

**Figure 11: Visualization of the amount of ages in the dataset used in the project after
being 26-year-old values were reduced.**
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/f316d805-8377-4f87-b16a-653295518129)

```
Sample the amount of images of 1-year olds by 70%
```
**Figure 12: Visualization of the amount of ages in the dataset used in the project after
being 1-year-old values were reduced.**


14. Create an age range.
15. Count the total number of images in the dataset after the sampling.
16. Preparing the images by applying greyscaling and converting the age values and
    images to numpy arrays
17. Display an example of the image after augmentation.
18. Splitting the data into test and train sets. First the ages are converted to a list. For each
    age in the list, it is going to be converted into a values that corresponds to an age
    range. The new list is printed. The data is then split into test and train. With 70%/30%
    split and stratifies or organizes data fairly so there is no imbalance in a dataset.
19. One-hot encoding enables better processing of categorical data by converting the
    values to binary vectors.
20. Convolutional neural network architecture, This contains four convolutional layers,
    Four average pooling layers, One global pooling layer and Two dense layers
21. Compiling the CCN and applies the categorical cross entropy loss, adam optimizer
    and metric to monitor and keep track of.
22. Creating a folder to save the model structure.


23. Printing and saving the model structure to the folder

![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/d09576ad-c889-4676-bebb-8ac2ce857224)

```
Figure 13: Model summary that is based off the neural network used in the project.
```
24. Creating a folder to save the model checkpoints.
25. Creating a model checkpoint callback which saves the model weight, saves the best
    weights and manages how much information is displayed about the iteration.
26. Training the model, The model is trained by separating the batch size into 64 batches.
    The amount of epochs is defined which contains the amount of iterations needed. The
    model results are saved to the checkpoints folder. The training data and validation
    data is defined. Shuffle is set to true which changes the order of the images and mixes
    them up.
27. The model results are plotted using line plots which describe the accuracy and loss of
    the test and train splits.
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/045d4d70-759a-4898-813a-0e96fb58111c)

**Figure 14: Plotting the model after training and displaying the loss and accuracy
of the CNN by epochs.**

28. A folder is created to store the trained model.
29. The model is saved to the folder.
30. A folder is created to save the model summary.
31. The model summary is printed and is saved to the folder.
32. The model is evaluated which returns the loss values and metric of the model.
33. The summary of the evaluation results is printed.
34. A folder is created to store the confusion matrix
35. The confusion matrix is created and displayed; it is then saved to the folder.

![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/b1b8ed26-12c3-4e8e-8a93-e433cb529a08)

```
Figure 15: A confusion matrix that is used in the project that measures the overall
correct predictions.
```
According to the matrix, the model measured that 22,455 images were correctly predicted
and matched their predicted label to their true label for age ranges 28-49.

The model accurately predicted that 5138 images matched their predicted label to their
true label for age ranges 17-27.

11,511 images were incorrectly predicted and classified. This was for the age range 0-16.

False positives is the amount calculated as having the prediction as true while actually
being false.

False negatives is the amount calculated as having the prediction as false while actually
being true.

36. The user uploads a picture, it is then displayed.
37. The classes are mapped to a string.
38. The image is then resized and converts the image to a numpy array and applies
    greyscaling to the image.
39. It is then normalized and reshaped.
40. It is passed to the model and the model makes a prediction which is then displayed.


41. The model tests its own data by predicting the age of ten images and prints the age
    and actual age for comparison.
42. There is functionality that allows the folders to be saved as a zip so they can be
    downloaded.

## Conclusion

The model attained a satisfactory level of accuracy during training on its validation set;
however, it struggled to make accurate predictions when presented with new data. Moreover,
its performance was subpar when tested against its own dataset. Several factors may have
contributed to these shortcomings, including the quality and quantity of the training data, the
architecture of the convolutional neural network, as well as limitations in available resources
such as RAM and GPU capacity. Given additional time and further education, there is
potential that the accuracy of the model could produce more favourable results.


## Testing Chapter

### Introduction

### Types of testing used in the project

### Objectives:

- Assess the model's accuracy with new and existing data.
- Generate an overall performance score through rapid evaluation.

### Types of Testing

Acceptance Testing: Evaluates if the model fulfils the project's objective.

- New Data Testing: Analysed the model's prediction accuracy for a new image.
- Existing Data Testing: Compared the model's predictions with the actual ages of ten
    images from the dataset.

Smoke Testing: Performed a quick evaluation of the model's performance using:

- Confusion Matrix: Visualized the distribution of correct and incorrect predictions
    across different age ranges.
- Classification Report: Provided detailed metrics (precision, recall, F1-score) for
    each age range class.

### Methods

During the Testing phase new data was introduced to see how accurate the model is at
predicting the age range of a new person.

#### Accepting testing – Testing New Data.

An image of my face was uploaded and processed by the model then the model had to predict
the age of my face.

The image was resized, grayscale added and reshaped.

### Expected results

The model would accurately predict the age range of the new data that was processed.


### Actual results

The model did not accurately predict the age range of the new data. my age is 28. The model
predicts I belong in the 0-16 age range.
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/9824378d-6868-4a09-aa42-bd3d5c7e731e)

```
Image 1: an image of my face show the predicted age range.
```
### Possible cause and solution

There are several possibilities why this is not accurately, this may be due to amount of data
used to train the model, the small amount of classes created and the quality of the data.
Improving this may product more desirable results

### Acceptance testing – Testing against the models own data.

Ten images are selected from the dataset and the model predicts what age range they belong
in, and the actual age is printed for comparison.

### Expected results

The model would accurately predict the age range of the images that were selected.

### Actual results

The model did not accurately predict the age range of the image data.

![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/4a43a008-a96e-4421-9bf6-4c390c39bf9d)

```
Index: 0, Original Age: 28,
Predicted Age: 0
```
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/d1f332d7-da11-41c3-8fed-c93966e69288)

```
Index: 1, Original Age:
28, Predicted Age: 0
```
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/40e4bf86-71e1-43b1-8519-9690f2a6295a)

```
Index: 2, Original Age: 5,
Predicted Age: 1
```
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/57e8c6ba-4f86-4540-a73f-084b405b4df1)

```
Index: 3, Original Age: 38,
Predicted Age: 0
```
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/8952381e-d3ec-4e69-946b-734aaf8d45e0)

```
Index: 5, Original Age:
21, Predicted Age: 0
```
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/8ad10a9d-9ffd-4231-829c-ba6c54ee7073)

```
Index: 6, Original Age: 1,
Predicted Age: 1
```
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/13b6a149-8a0b-49da-b39f-60a3a4f58778)
```
Index: 4, Original Age: 35,
Predicted Age: 0
```
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/58cd9098-e21b-42bb-907d-01619e1e678c)

```
Index: 7, Original Age:
29,Predicted Age: 0
```
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/4d53d66e-e18e-43bf-8abb-2ec54516f66c)
```
Index: 8, Original Age: 32,
Predicted Age: 0
```
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/fdfb6674-6b53-42c6-933c-04bf29245c01)

```
Index: 9, Original Age: 2,
Predicted Age: 1


```
Table: Table containing the images that were tested and the index at which they were
stored and the images original age and predicted age.

#### Possible cause and solution

There are several possibilities why this is not accurately, The quality of the data, the data that
was sampled may not be needed as this can reduce the accuracy for those age ranges.

### Smoke testing – Creating a Confusion Matrix and Classification Report

A confusion matrix was generated to find out how the model classified images. This allows
quick testing to see how the model is scoring in terms of accuracy.

A classification report was generated with the matrix which shows different scores and
metrics

#### Expected results

The model would accurately predict the age range of the images that were selected and show
a high level of accuracy and images that were True positives.


#### Actual results


![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/570dae36-52c0-4020-b9b6-554179643b04)


**2. Image of confusion matrix used in the project**

According to the matrix, the model measured that 22,455 images were correctly predicted
and matched their predicted label to their true label for age ranges 28-49.

The model accurately predicted that 5138 images matched their predicted label to their true
label for age ranges 17-27.

11,511 images were incorrectly predicted and classified. This was for the age range 0-16.


### Classification report
![image](https://github.com/CharleyRutledge/Age-Prediction-System/assets/99267310/5d3f0131-86f7-4f2b-9a79-f0447688104e)

```
Image showing the scores of the classification report.
```
### Classes:

```
Class 0
Class 1
Class 2
```
### Metrics:

#### Precision

This metric measures the proportion of predicted positives that were actually correct.

#### Recall

This metric measures the proportion of actual positives that were correctly identified by the
model.

#### F1-score

This metric is the harmonic mean of precision and recall, aiming to balance both metrics into
a single score.

#### Support

This represents the total number of true instances for a specific class in the testing data.


### Interpretation:

#### Class 0 (0-16):

The model has a moderate precision (0.59), meaning it sometimes predicts Class 0 when it
should not.

The model has a moderate recall (0.52), indicating it misses some actual Class 0 instances in
the data.

The F1-score (0.55) suggests a balanced performance between precision and recall for Class
0, but there is still room for significant improvement.

#### Class 1 (17-27):

The model has a high precision (0.95), indicating it rarely predicts Class 1 when it should not.

The model has a moderate recall (0.87), meaning it misses some actual Class 1 instances in
the data.

The F1-score (0.91) suggests a good balance between precision and recall for Class 1.

#### Class 2 (28-49):

The model has a moderate precision (0.81), meaning it sometimes predicts Class 2 when it
should not.

The model has a high recall (0.89), indicating it identifies most of the actual Class 2 instances
in the data.

The F1-score (0.85) suggests a moderate balance between precision and recall for Class 2.

### Conclusion:

The model exhibited poor performance in both new and existing data when tested. The
confusion matrix and classification report highlighted a substantial amount of
misclassification, particularly for ages outside of the 17-27 and 0-16 age range.

Solutions to improve the model’s accuracy would be to examine the dataset and the
distribution to find potential outliers or potential biases, increasing the number of classes to
better capture variations in age ranges and further experimentation with different techniques
in the model’s ability to learn and generalize from the data.


## Discussion

The widespread use of social media platforms has revolutionized communication and
connectivity, yet it has also raised significant concerns regarding online safety, particularly
for minors. The unrestricted access to potentially harmful or age-inappropriate content poses
a serious risk to the well-being of children. This project aims to tackle this issue by proposing
innovative solutions to enhance the security measures and age verification processes
employed by social media platforms.

The testing phase of this final year project unveiled significant insights into the performance
of my proposed solution, revealing areas where improvements are imperative. Despite the
initial setback of poor performance, these findings are invaluable as they guide toward
enhancing the efficacy and reliability of our security measures and age verification protocols
on social media platforms.

I encountered challenges and observed shortcomings in the accuracy and efficiency of my age
verification mechanisms and algorithms. These issues underscore the complexity of the task
at hand and emphasize the need for further refinement and optimization.

Furthermore, I recognize the importance of collaboration with stakeholders and other
developers to address these performance issues comprehensively. Engaging with social media
platforms, regulatory bodies, and child protection organizations would provide valuable
insights and guidance in my efforts to overcome these challenges and improve the overall
efficacy of my solution.

While the poor performance observed during testing may present a setback, it also serves as a
catalyst for innovation and improvement. By embracing these challenges head-on and
leveraging the lessons learned from testing, It is important to remain steadfast in commitment
to developing robust security measures and age verification protocols that effectively
safeguard minors from accessing inappropriate content on social media platforms.


## Conclusion

This project successfully explored the potential and limitations of machine learning in age
recognition. While the model achieved a basic functional capability, further development is
necessary to enhance its ability to perform accurately on unseen data.

Key Findings:

Data Constraints: The model's performance was limited by the restricted size and potential
bias within the available labelled data. This restricted the model's ability to learn and
generalize effectively to broader age ranges and variations.

Computational Limitations: Resource constraints, such as occasional RAM limitations
encountered on Google Collab’s GPUs, presented challenges during training.

Areas for Improvement:

Data Augmentation: Utilizing larger and more diverse datasets, such as Microsoft's Digiface
1Million (Bae et al. 2022), could significantly improve the model's ability to generalize to
unseen data.

Hardware Acceleration: Employing more powerful computing resources would expedite the
training process and potentially allow for the development of more complex models that can
handle the intricacies of age recognition.

Collaboration: Collaborative efforts with other researchers could lead to the development of
more robust and efficient models, potentially incorporating techniques to address data bias
and improve generalizability.

Overall, this project provided valuable insights into the challenges of achieving
generalizability in machine learning models, particularly in the context of age recognition
using facial data. The learnings gained will contribute to future endeavours in this domain.


## Reference list

Advertising Standards Authority | Committee of Advertising Practice (2013) _ASA research
shows children are registering on social media under false ages_ , _ASA_. Available at:
https://www.asa.org.uk/news/asa-research-shows-children-are-registering-on-social-media-
under-false-
ages.html#:~:text=In%20summary%2C%20our%20survey%20reveals,as%20aged%2018%2
0or%20over (Accessed: 24 October 2023).

Bae, G., De La Gorce, M., Baltrušaitis , T., Hewitt, C. and Chen, D. (2022). DigiFace-1M.
[online] microsoft.github.io. Available at: https://microsoft.github.io/DigiFace1M/.

AI, S. (2022). _Age Detection Model using CNN — a complete guide_. [online] Medium.
Available at: https://medium.com/@skillcate/age-detection-model-using-cnn-a-complete-
guide-7b10ad717c60.

B. Abirami, Subashini, T.S. and V. Mahavaishnavi (2020). Gender and age prediction from
real time facial images using CNN. _Materials Today: Proceedings_ , [online] 33, pp.4708–

4712. doi:https://doi.org/10.1016/j.matpr.2020.08.350.

Brownlee, J. (2017). _Why One-Hot Encode Data in Machine Learning?_ [online] Machine
Learning Mastery. Available at: https://machinelearningmastery.com/why-one-hot-encode-
data-in-machine-learning/.

Caglar, C. (2021) _Digital age of consent under the GDPR_ , _EuConsent_. Available at:
https://euconsent.eu/digital-age-of-consent-under-the-gdpr/ (Accessed: 25 October 2023).

Clark, A. (2024). _Pillow: Python Imaging Library (Fork)_. [online] PyPI. Available at:
https://pypi.org/project/Pillow/.

Cloud, S. (2023). _Understanding the Difference Between Flatten() and
GlobalAveragePooling2D() in Keras | Saturn Cloud Blog_. [online] saturncloud.io. Available
at: https://saturncloud.io/blog/understanding-the-difference-between-flatten-and-
globalaveragepooling2d-in-keras/#2 [Accessed 3 Feb. 2024].

Costa-Luis, C. da (2015). _tqdm.notebook - tqdm documentation_. [online] tqdm.github.io.
Available at: https://tqdm.github.io/docs/notebook/ [Accessed 29 Jan. 2024].


Datacamp.com. (2024). _Adjusting the number of bins in a histogram | Python_. [online]
Available at: https://campus.datacamp.com/courses/statistical-thinking-in-python-part-
1/graphical-exploratory-data-
analysis?ex=7#:~:text=The%20%22square%20root%20rule%22%20is,for%20the%20numbe
r%20of%20bins. [Accessed 20 Feb. 2024].

Data Protection Commission (2023) ‘Children’s data and parental consent’. dublin: Data
Protection Commission.

Deloitte (2017) ‘2017 Global Mobile Consumer Survey: US edition The dawn of the next era
in mobile’. London: Deloitte.

DFA (n.d.). _Passport Card - Department of Foreign Affairs_. [online] [http://www.dfa.ie.](http://www.dfa.ie.) Available
at: https://www.dfa.ie/irish-embassy/great-britain/passports/passportcard/ [Accessed 3 Oct.
2023].

euConsent (2023). _New non-profit organisation born to take forward the work of
euCONSENT_. [online] EuConsent. Available at: https://euconsent.eu/new-non-profit-
organization-born-to-take-forward-the-work-of-euconsent/ [Accessed 6 Mar. 2024].

Fernando, S.R. (n.d.). _Introduction_. [online] Available at: https://www.opencv-
srf.com/p/introduction.html.

GeeksforGeeks. (2020). _Python Keras keras.utils.to categorical_. [online] Available at:
https://www.geeksforgeeks.org/python-keras-keras-utils-to_categorical/ [Accessed 31 Jan.
2024].

GeeksforGeeks. (2020). _VGG 16 CNN model_. [online] Available at:
https://www.geeksforgeeks.org/vgg- 16 - cnn-model/ [Accessed 2 Nov. 2023].

Google.com. (2019). _Google Colaboratory_. [online] Available at:
https://colab.research.google.com/github/dphi-
official/Deep_Learning_Bootcamp/blob/master/OpenCV/DL_Day12_OpenCV.ipynb#scrollT
o=fyjSR5plNWOl [Accessed 31 Jan. 2024].

_Guidance on legal bases for processing personal data: Data Protection Commission_ (no
date) _Guidance on Legal Bases for Processing Personal Data | Data Protection Commission_.


Available at: https://www.dataprotection.ie/en/dpc-guidance/guidance-legal-bases-
processing-personal-
data#:~:text=Article%206%20of%20the%20General,public%20task%3B%20or%20legitimat
e%20interests. (Accessed: 23 October 2023).

H2o.ai. (2023). _What is Forward Propagation? | H2O.ai_. [online] Available at:
https://h2o.ai/wiki/forward-propagation/ [Accessed 4 Nov. 2023].

Hunter, J., Dale, D., Firing, E. and Droettboom, M. (2012). _matplotlib.pyplot — Matplotlib
3.5.3 documentation_. [online] matplotlib.org. Available at:
https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html.

Ibm.com. (2023). _What are Neural Networks? | IBM_. [online] Available at:
https://www.ibm.com/topics/neural-networks [Accessed 2 Nov. 2023].

Javapoint (n.d.). _TensorFlow Tutorial - Javatpoint_. [online] [http://www.javatpoint.com.](http://www.javatpoint.com.) Available
at: https://www.javatpoint.com/tensorflow.

Kaggle (n.d.). _Public API Documentation_. [online] [http://www.kaggle.com.](http://www.kaggle.com.) Available at:
https://www.kaggle.com/docs/api.

Kanan, C. and Cottrell, G.W. (2012). Color-to-Grayscale: Does the Method Matter in Image
Recognition? _PLoS ONE_ , 7(1), p.e29740. doi:https://doi.org/10.1371/journal.pone.0029740.

Kingma, D.P. and Ba, J., 2014. Adam: A method for stochastic optimization. _arXiv preprint
arXiv:1412.6980_.

Knowledgehut.com. (2023). _What is Padding in Convolutional Neural Networks (CNN)?_
[online] Available at: https://www.knowledgehut.com/blog/data-science/padding-in-cnn
[Accessed 5 Nov. 2023].

Mamon, Q. (n.d.). _Educative Answers - Trusted Answers to Developer Questions_. [online]
Educative. Available at: https://www.educative.io/answers/keras-dense-layer.

Mani, V.R.S., Saravanaselvan, A. and Arumugam, N. (2021). Performance comparison of
CNN, QNN and BNN deep neural networks for real-time object detection using ZYNQ
FPGA node. _Microelectronics Journal_ , p.105319.
doi:https://doi.org/10.1016/j.mejo.2021.105319.


McFarlin, L.A., Buffardi, K.J. and Schumacher, R.M. (2007) ‘Usability impact on
effectiveness of parental controls’, _Proceedings of the Human Factors and Ergonomics
Society Annual Meeting_ , 51(17), pp. 1039–1043. doi:10.1177/154193120705101709.

Mishra, M. (2020). _Convolutional Neural Networks, Explained_. [online] Medium. Available
at: https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939.

Negreiro, M. (2023). _AT A GLANCE Digital issues in focus_. [online] Available at:
https://www.europarl.europa.eu/RegData/etudes/ATAG/2023/739350/EPRS_ATA(2023)739
350_EN.pdf.

OpenCV (2018). _About OpenCV_. [online] OpenCV. Available at: https://opencv.org/about/.

Opencv.org. (2023). _CNN Fundamentals | CNN Fundamentals | Free Tensorflow Keras
Bootcamp Courseware | OpenCV_. [online] Available at:
https://courses.opencv.org/courses/course-
v1:Tensorflow+Bootcamp+TFKS/courseware/f7a0faad74eb496aa3795bb77144a236/4be13b
b4918348fcbb0dddad42bde295/1?activate_block_id=block-
v1%3ATensorflow%2BBootcamp%2BTFKS%2Btype%40vertical%2Bblock%4040f35c1884
b448229437e8930750d31d [Accessed 2 Nov. 2023].

Oprea, A. (2022) _EUCONSENT’s first large scale pilot_ , _EuConsent_. Available at:
https://euconsent.eu/euconsents-first-large-scale-pilot/ (Accessed: 26 October 2023).

Pasquale, L. _et al._ (2022) ‘Digital age of consent and age verification: Can they protect
children?’, _IEEE Software_ , 39(3), pp. 50–57. doi:10.1109/ms.2020.3044872.

Python Software Foundation (2024a). _5. The import system — Python 3.9.2 documentation_.
[online] docs.python.org. Available at: https://docs.python.org/3/reference/import.html.

Python Software Foundation (2024b). _File and Directory Access_. [online] Python
documentation. Available at: https://docs.python.org/3/library/filesys.html.

Raj, A. (2023) _How should businesses build a chatbot for websites_ , _Tech Wire Asia_.
Available at: https://techwireasia.com/2023/09/chatbot-for-websites-can-ai-simplify-
cms/#:~:text=Almost%20all%20websites%20today%20have,customers%20interacting%20w
ith%20a%20chatbot. (Accessed: 23 October 2023).


Refsnes Data (2024). _Introduction to NumPy_. [online] [http://www.w3schools.com.](http://www.w3schools.com.) Available at:
https://www.w3schools.com/python/numpy/numpy_intro.asp#:~:text=NumPy%20is%20a%2
0Python%20library.

scikit-learn. (2024). _sklearn.model_selection.train_test_split_. [online] Available at:
https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html
[Accessed 31 Jan. 2024].

seaborn (2012). _seaborn: statistical data visualization — seaborn 0.9.0 documentation_.
[online] Pydata.org. Available at: https://seaborn.pydata.org/.

Soni, D. (2019). _Translation Invariance in Convolutional Neural Networks_. [online] Medium.
Available at: https://divsoni2012.medium.com/translation-invariance-in-convolutional-
neural-networks-61d9b6fa03df [Accessed 2 Nov. 2023].

Strauss, M. (2023) _France moves to block access to pornography sites for minors_ , _Reuters_.
Available at: https://www.reuters.com/world/europe/france-moves-block-access-
pornography-sites-minors- 2023 - 02 - 06/ (Accessed: 25 October 2023).

Superdatascience.com. (2023). _SuperDataScience_. [online] Available at:
https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-1b-relu-
layer [Accessed 5 Nov. 2023].

Team, K. (2020). _Keras documentation: The Sequential model_. [online] Keras.io. Available
at: https://keras.io/guides/sequential_model/ [Accessed 31 Jan. 2024].

Team, K. (2024). _Keras documentation: Conv2D layer_. [online] keras.io. Available at:
https://keras.io/api/layers/convolution_layers/convolution2d/.

Team, K. (2024). _Keras documentation: Model plotting utilities_. [online] Keras.io. Available
at: https://keras.io/api/utils/model_plotting_utils/ [Accessed 31 Jan. 2024].

Team, K. (2024). _Keras documentation: AveragePooling2D layer_. [online] Keras.io.
Available at: https://keras.io/api/layers/pooling_layers/average_pooling2d/ [Accessed 3 Feb.
2024].

Team, K. (2024). _Keras documentation: ModelCheckpoint_. [online] Keras.io. Available at:
https://keras.io/api/callbacks/model_checkpoint/ [Accessed 3 Feb. 2024].


Team, K. (2024). _Keras documentation: TensorBoard_. [online] Keras.io. Available at:
https://keras.io/api/callbacks/tensorboard/ [Accessed 3 Feb. 2024].

Team, K. (2024). _Keras documentation: Probabilistic losses_. [online] Keras.io. Available at:
https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class [Accessed 3
Feb. 2024].

Team, K. (2024). _Keras documentation: Accuracy metrics_. [online] Keras.io. Available at:
https://keras.io/api/metrics/accuracy_metrics/#categoricalaccuracy-class [Accessed 5 Feb.
2024].

Team, K. (2024). _Keras documentation: Accuracy metrics_. [online] Keras.io. Available at:
https://keras.io/api/metrics/accuracy_metrics/ [Accessed 19 Feb. 2024].

Team, K. (2024). _Keras documentation: Model training APIs_. [online] Keras.io. Available at:
https://keras.io/api/models/model_training_apis/ [Accessed 19 Feb. 2024].

The, H. (2017). _A guide to receptive field arithmetic for Convolutional Neural Networks_.
[online] Medium. Available at: https://blog.mlreview.com/a-guide-to-receptive-field-
arithmetic-for-convolutional-neural-networks-e0f514068807 [Accessed 4 Nov. 2023].

W3schools.com. (2022). _Pandas DataFrames_. [online] Available at:
https://www.w3schools.com/python/pandas/pandas_dataframes.asp [Accessed 29 Jan. 2024].

W3schools.com. (2024). _Python Machine Learning - Confusion Matrix_. [online] Available at:
https://www.w3schools.com/python/python_ml_confusion_matrix.asp [Accessed 19 Feb.
2024].

W3Schools (n.d.). _W3Schools online PYTHON editor_. [online] [http://www.w3schools.com.](http://www.w3schools.com.)
Available at:
https://w3schools.com/python/pandas/trypython.asp?filename=demo_pandas_series_label
[Accessed 29 Jan. 2024].

W&B. (2024). _Weights & Biases_. [online] Available at:
https://wandb.ai/mostafaibrahim17/ml-articles/reports/A-Deep-Dive-Into-Learning-Curves-
in-Machine-Learning--
Vmlldzo0NjA1ODY0#:~:text=Training%20Loss%20Decreases%2C%20Validation%20Loss


%20Plateaus,-
%EF%BB%BF&text=If%20the%20training%20loss%20decreases,generalize%20well%20to
%20new%20data. [Accessed 19 Feb. 2024].

Yamashita, R., Nishio, M., Do, R.K.G. and Togashi, K. (2018). Convolutional neural
networks: an overview and application in radiology. _Insights into Imaging_ , 9(4), pp.611–629.
doi:https://doi.org/10.1007/s13244- 018 - 0639 - 9.

Yegulalp, S. (2018). _What is TensorFlow? The machine learning library explained_. [online]
InfoWorld. Available at: https://www.infoworld.com/article/3278008/what-is-tensorflow-the-
machine-learning-library-explained.html.

Yi, D., Lei, Z. and Li, S. (2015). _Age Estimation by Multi-scale Convolutional Network_.
[online] Available at: [http://www.cbsr.ia.ac.cn/users/zlei/papers/ACCV2014/Yi-ACCV-](http://www.cbsr.ia.ac.cn/users/zlei/papers/ACCV2014/Yi-ACCV-)
14.pdf.

Zimmergren (2023). _Introduction - Training_. [online] Microsoft.com. Available at:
https://learn.microsoft.com/en-us/training/modules/sustainable-software-engineering-
overview/1-introduction [Accessed 1 Nov. 2023].


